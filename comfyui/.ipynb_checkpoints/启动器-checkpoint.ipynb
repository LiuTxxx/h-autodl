{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f19ac5-41e3-4f66-bf18-14ec6c540d6d",
   "metadata": {},
   "source": [
    "## 说明\n",
    "\n",
    "![](https://oss.talesofai.cn/public/s_2023-04-13%20at%2022.28.22.png?cc0429)\n",
    "- 启动和重启 webui 点上方工具栏中的「重启并运行所有单元格」。出现 `http://0.0.0.0:6006` 这个字样就算成功了。可以去 autodl 控制台打开「自定义服务」了\n",
    "- 首次启动需要下载基本的模型，请稍等几分钟\n",
    "- 镜像在 4090, A5000, 3090, 3080 上测试没问题\n",
    "- 模型路径：`/root/autodl-tmp/models` 里的对应目录下\n",
    "- 生成文件路径：`/root/ComfyUI/output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e92188e-2325-4d48-8f17-5f56bc630418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化环境中...\n",
      "删除原有ComfyUI环境...\n",
      "准备下载: custom_nodes\n",
      "<<<<<dw-ll_ucoco_384_bs5.torchscript.pt\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "downloading file [H-custom_nodes/dw-ll_ucoco_384_bs5.torchscript.pt]\n",
      "downloading... 100% 129 MiB/129 MiB\n",
      "<<<<<body_pose_model.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/body_pose_model.pth\n",
      "downloading file [H-custom_nodes/body_pose_model.pth]\n",
      "downloading... 100% 200 MiB/200 MiB\n",
      "<<<<<hand_pose_model.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/hand_pose_model.pth\n",
      "downloading file [H-custom_nodes/hand_pose_model.pth]\n",
      "downloading... 100% 141 MiB/141 MiB\n",
      "<<<<<facenet.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/facenet.pth\n",
      "downloading file [H-custom_nodes/facenet.pth]\n",
      "downloading... 100% 147 MiB/147 MiB\n",
      "<<<<<ControlNetHED.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/ControlNetHED.pth\n",
      "downloading file [H-custom_nodes/ControlNetHED.pth]\n",
      "downloading... 100% 28 MiB/28 MiB\n",
      "<<<<<ZoeD_M12_N.pt\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/ZoeD_M12_N.pt\n",
      "downloading file [H-custom_nodes/ZoeD_M12_N.pt]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<yolox_l.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/yolox_l.onnx\n",
      "downloading file [H-custom_nodes/yolox_l.onnx]\n",
      "downloading... 100% 207 MiB/207 MiB\n",
      "<<<<<wd-v1-4-moat-tagger-v2.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/wd-v1-4-moat-tagger-v2.onnx\n",
      "downloading file [H-custom_nodes/wd-v1-4-moat-tagger-v2.onnx]\n",
      "downloading... 100% 311 MiB/311 MiB\n",
      "<<<<<wd-v1-4-convnext-tagger-v2.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-custom_nodes/wd-v1-4-convnext-tagger-v2.onnx\n",
      "downloading file [H-custom_nodes/wd-v1-4-convnext-tagger-v2.onnx]\n",
      "downloading... 100% 370 MiB/370 MiB\n",
      ">>>> custom_nodes 下载完毕\n",
      "\n",
      "准备下载: checkpoint_sd15\n",
      "<<<<<majicmixRealistic_v7.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-SD15-checkpoints/majicmixRealistic_v7.safetensors\n",
      "downloading file [H-SD15-checkpoints/majicmixRealistic_v7.safetensors]\n",
      "downloading... 100% 2.0 GiB/2.0 GiBiB\n",
      ">>>> checkpoint_sd15 下载完毕\n",
      "\n",
      "准备下载: checkpoint_sdxl\n",
      "<<<<<LEOSAM_HelloWorld_SDXL_v7.0.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-SDXL-checkpoints/LEOSAM_HelloWorld_SDXL_v7.0.safetensors\n",
      "downloading file [H-SDXL-checkpoints/LEOSAM_HelloWorld_SDXL_v7.0.safetensors]\n",
      "downloading... 100% 6.5 GiB/6.5 GiBiB\n",
      ">>>> checkpoint_sdxl 下载完毕\n",
      "\n",
      "准备下载: controlnet_sd15_v11_lite\n",
      "<<<<<control_hed.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_hed.safetensors\n",
      "downloading file [H-controlnet/control_hed.safetensors]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11f1e_sd15_tile.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11f1e_sd15_tile.pth\n",
      "downloading file [H-controlnet/control_v11f1e_sd15_tile.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11f1p_sd15_depth.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11f1p_sd15_depth.pth\n",
      "downloading file [H-controlnet/control_v11f1p_sd15_depth.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_canny.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_canny.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_canny.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_inpaint.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_inpaint.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_inpaint.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_lineart.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_lineart.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_lineart.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_openpose.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_openpose.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_openpose.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_scribble.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_scribble.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_scribble.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_seg.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_seg.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_seg.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11p_sd15_softedge.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_softedge.pth\n",
      "downloading file [H-controlnet/control_v11p_sd15_softedge.pth]\n",
      "downloading... 100% 1.3 GiB/1.3 GiBiB\n",
      "<<<<<control_v11f1e_sd15_tile.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11f1e_sd15_tile.yaml\n",
      "downloading file [H-controlnet/control_v11f1e_sd15_tile.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11f1p_sd15_depth.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11f1p_sd15_depth.yaml\n",
      "downloading file [H-controlnet/control_v11f1p_sd15_depth.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_canny.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_canny.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_canny.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_inpaint.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_inpaint.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_inpaint.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_lineart.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_lineart.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_lineart.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_openpose.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_openpose.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_openpose.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_scribble.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_scribble.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_scribble.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_seg.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_seg.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_seg.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      "<<<<<control_v11p_sd15_softedge.yaml\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-controlnet/control_v11p_sd15_softedge.yaml\n",
      "downloading file [H-controlnet/control_v11p_sd15_softedge.yaml]\n",
      "downloading... 100% 1.9 KiB/1.9 KiB\n",
      ">>>> controlnet_sd15_v11_lite 下载完毕\n",
      "\n",
      "准备下载: sams\n",
      "<<<<<sam_vit_h_4b8939.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-sams/sam_vit_h_4b8939.pth\n",
      "downloading file [H-sams/sam_vit_h_4b8939.pth]\n",
      "downloading... 100% 2.4 GiB/2.4 GiBiB\n",
      "<<<<<sam_vit_l_0b3195.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-sams/sam_vit_l_0b3195.pth\n",
      "downloading file [H-sams/sam_vit_l_0b3195.pth]\n",
      "downloading... 100% 1.2 GiB/1.2 GiBiB\n",
      "<<<<<sam_vit_b_01ec64.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-sams/sam_vit_b_01ec64.pth\n",
      "downloading file [H-sams/sam_vit_b_01ec64.pth]\n",
      "downloading... 100% 358 MiB/358 MiB\n",
      ">>>> sams 下载完毕\n",
      "\n",
      "准备下载: grounding-dino\n",
      "<<<<<groundingdino_swinb_cogcoor.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "downloading file [H-grounding-dino/groundingdino_swinb_cogcoor.pth]\n",
      "downloading... 100% 895 MiB/895 MiBiB\n",
      "<<<<<groundingdino_swint_ogc.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-grounding-dino/groundingdino_swint_ogc.pth\n",
      "downloading file [H-grounding-dino/groundingdino_swint_ogc.pth]\n",
      "downloading... 100% 662 MiB/662 MiBiB\n",
      "<<<<<GroundingDINO_SwinB.cfg.py\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "downloading file [H-grounding-dino/GroundingDINO_SwinB.cfg.py]\n",
      "downloading... 100% 1007 B/1007 B\n",
      "<<<<<GroundingDINO_SwinT_OGC.cfg.py\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-grounding-dino/GroundingDINO_SwinT_OGC.cfg.py\n",
      "downloading file [H-grounding-dino/GroundingDINO_SwinT_OGC.cfg.py]\n",
      "downloading... 100% 1006 B/1006 B\n",
      ">>>> grounding-dino 下载完毕\n",
      "\n",
      "准备下载: facerestore\n",
      "<<<<<GFPGANv1.3.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-facerestore_models/GFPGANv1.3.pth\n",
      "downloading file [H-facerestore_models/GFPGANv1.3.pth]\n",
      "downloading... 100% 332 MiB/332 MiB\n",
      "<<<<<GFPGANv1.4.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-facerestore_models/GFPGANv1.4.pth\n",
      "downloading file [H-facerestore_models/GFPGANv1.4.pth]\n",
      "downloading... 100% 332 MiB/332 MiB\n",
      "<<<<<codeformer-v0.1.0.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-facerestore_models/codeformer-v0.1.0.pth\n",
      "downloading file [H-facerestore_models/codeformer-v0.1.0.pth]\n",
      "downloading... 100% 359 MiB/359 MiB\n",
      "<<<<<GPEN-BFR-512.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-facerestore_models/GPEN-BFR-512.onnx\n",
      "downloading file [H-facerestore_models/GPEN-BFR-512.onnx]\n",
      "downloading... 100% 271 MiB/271 MiB\n",
      "<<<<<GPEN-BFR-1024.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-facerestore_models/GPEN-BFR-1024.onnx\n",
      "downloading file [H-facerestore_models/GPEN-BFR-1024.onnx]\n",
      "downloading... 100% 272 MiB/272 MiB\n",
      "<<<<<GPEN-BFR-2048.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-facerestore_models/GPEN-BFR-2048.onnx\n",
      "downloading file [H-facerestore_models/GPEN-BFR-2048.onnx]\n",
      "downloading... 100% 272 MiB/272 MiB\n",
      ">>>> facerestore 下载完毕\n",
      "\n",
      "准备下载: ic-light_lite\n",
      "<<<<<iclight_sd15_fc.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-ICLight/iclight_sd15_fc.safetensors\n",
      "downloading file [H-ICLight/iclight_sd15_fc.safetensors]\n",
      "downloading... 100% 1.6 GiB/1.6 GiBiB\n",
      ">>>> ic-light_lite 下载完毕\n",
      "\n",
      "准备下载: instantid\n",
      "<<<<<diffusion_pytorch_model.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-instantID/diffusion_pytorch_model.safetensors\n",
      "downloading file [H-instantID/diffusion_pytorch_model.safetensors]\n",
      "downloading... 100% 2.3 GiB/2.3 GiBiBB\n",
      "<<<<<ip-adapter.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-instantID/ip-adapter.bin\n",
      "downloading file [H-instantID/ip-adapter.bin]\n",
      "downloading... 100% 1.6 GiB/1.6 GiBiB\n",
      ">>>> instantid 下载完毕\n",
      "\n",
      "准备下载: insightface\n",
      "<<<<<inswapper_128.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/inswapper_128.onnx\n",
      "downloading file [H-insightface/inswapper_128.onnx]\n",
      "downloading... 100% 529 MiB/529 MiBiB\n",
      "<<<<<1k3d68.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/1k3d68.onnx\n",
      "downloading file [H-insightface/1k3d68.onnx]\n",
      "downloading... 100% 137 MiB/137 MiB\n",
      "<<<<<2d106det.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/2d106det.onnx\n",
      "downloading file [H-insightface/2d106det.onnx]\n",
      "downloading... 100% 4.8 MiB/4.8 MiB\n",
      "<<<<<genderage.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/genderage.onnx\n",
      "downloading file [H-insightface/genderage.onnx]\n",
      "downloading... 100% 1.3 MiB/1.3 MiB\n",
      "<<<<<glintr100.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/glintr100.onnx\n",
      "downloading file [H-insightface/glintr100.onnx]\n",
      "downloading... 100% 249 MiB/249 MiBiB\n",
      "<<<<<scrfd_10g_bnkps.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/scrfd_10g_bnkps.onnx\n",
      "downloading file [H-insightface/scrfd_10g_bnkps.onnx]\n",
      "downloading... 100% 16 MiB/16 MiB\n",
      "<<<<<1k3d68.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/1k3d68.onnx\n",
      "downloading file [H-insightface/1k3d68.onnx]\n",
      "downloading... 100% 137 MiB/137 MiB\n",
      "<<<<<2d106det.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/2d106det.onnx\n",
      "downloading file [H-insightface/2d106det.onnx]\n",
      "downloading... 100% 4.8 MiB/4.8 MiB\n",
      "<<<<<genderage.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/genderage.onnx\n",
      "downloading file [H-insightface/genderage.onnx]\n",
      "downloading... 100% 1.3 MiB/1.3 MiB\n",
      "<<<<<det_10g.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/det_10g.onnx\n",
      "downloading file [H-insightface/det_10g.onnx]\n",
      "downloading... 100% 16 MiB/16 MiB\n",
      "<<<<<w600k_r50.onnx\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-insightface/w600k_r50.onnx\n",
      "downloading file [H-insightface/w600k_r50.onnx]\n",
      "downloading... 100% 166 MiB/166 MiB\n",
      ">>>> insightface 下载完毕\n",
      "\n",
      "准备下载: ipadapter_sd_lite\n",
      "<<<<<CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\n",
      "downloading file [H-IPAdapter/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors]\n",
      "downloading... 100% 2.4 GiB/2.4 GiBiB\n",
      "<<<<<ip-adapter-faceid_sd15_lora.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid_sd15_lora.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid_sd15_lora.safetensors]\n",
      "downloading... 100% 49 MiB/49 MiB\n",
      "<<<<<ip-adapter-faceid-plusv2_sd15_lora.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid-plusv2_sd15_lora.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid-plusv2_sd15_lora.safetensors]\n",
      "downloading... 100% 49 MiB/49 MiB\n",
      "<<<<<ip-adapter-faceid_sdxl_lora.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid_sdxl_lora.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid_sdxl_lora.safetensors]\n",
      "downloading... 100% 355 MiB/355 MiB\n",
      "<<<<<ip-adapter-faceid-plusv2_sdxl_lora.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid-plusv2_sdxl_lora.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid-plusv2_sdxl_lora.safetensors]\n",
      "downloading... 100% 355 MiB/355 MiB\n",
      "<<<<<ip-adapter_sd15.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter_sd15.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter_sd15.safetensors]\n",
      "downloading... 100% 43 MiB/43 MiB\n",
      "<<<<<ip-adapter_sd15_light_v11.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter_sd15_light_v11.bin\n",
      "downloading file [H-IPAdapter/ip-adapter_sd15_light_v11.bin]\n",
      "downloading... 100% 43 MiB/43 MiB\n",
      "<<<<<ip-adapter_sdxl_vit-h.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter_sdxl_vit-h.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter_sdxl_vit-h.safetensors]\n",
      "downloading... 100% 666 MiB/666 MiBiB\n",
      "<<<<<ip-adapter-plus_sdxl_vit-h.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-plus_sdxl_vit-h.safetensors\n",
      "downloading file [H-IPAdapter/ip-adapter-plus_sdxl_vit-h.safetensors]\n",
      "downloading... 100% 808 MiB/808 MiB\n",
      "<<<<<ip-adapter-faceid_sd15.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid_sd15.bin\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid_sd15.bin]\n",
      "downloading... 100% 92 MiB/92 MiB\n",
      "<<<<<ip-adapter-faceid-plusv2_sd15.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid-plusv2_sd15.bin\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid-plusv2_sd15.bin]\n",
      "downloading... 100% 149 MiB/149 MiB\n",
      "<<<<<ip-adapter-faceid_sdxl.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid_sdxl.bin\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid_sdxl.bin]\n",
      "downloading... 100% 1022 MiB/1022 MiBB\n",
      "<<<<<ip-adapter-faceid-plusv2_sdxl.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-IPAdapter/ip-adapter-faceid-plusv2_sdxl.bin\n",
      "downloading file [H-IPAdapter/ip-adapter-faceid-plusv2_sdxl.bin]\n",
      "downloading... 100% 1.4 GiB/1.4 GiBiB\n",
      ">>>> ipadapter_sd_lite 下载完毕\n",
      "\n",
      "准备下载: vae\n",
      "<<<<<vae-ft-mse-840000-ema-pruned.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-vae/vae-ft-mse-840000-ema-pruned.safetensors\n",
      "downloading file [H-vae/vae-ft-mse-840000-ema-pruned.safetensors]\n",
      "downloading... 100% 319 MiB/319 MiB\n",
      "<<<<<sdxl_vae.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-vae/sdxl_vae.safetensors\n",
      "downloading file [H-vae/sdxl_vae.safetensors]\n",
      "downloading... 100% 319 MiB/319 MiB\n",
      ">>>> vae 下载完毕\n",
      "\n",
      "准备下载: inpaint\n",
      "<<<<<random_mask_sd15.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-inpaint/random_mask_sd15.safetensors\n",
      "downloading file [H-inpaint/random_mask_sd15.safetensors]\n",
      "downloading... 100% 2.3 GiB/2.3 GiBiB\n",
      "<<<<<segmentation_mask_sd15.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-inpaint/segmentation_mask_sd15.safetensors\n",
      "downloading file [H-inpaint/segmentation_mask_sd15.safetensors]\n",
      "downloading... 100% 2.3 GiB/2.3 GiBiB\n",
      "<<<<<random_mask_sdxl.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-inpaint/random_mask_sdxl.safetensors\n",
      "downloading file [H-inpaint/random_mask_sdxl.safetensors]\n",
      "downloading... 100% 1.4 GiB/1.4 GiBiB\n",
      "<<<<<segmentation_mask_sdxl_v1.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-inpaint/segmentation_mask_sdxl_v1.safetensors\n",
      "downloading file [H-inpaint/segmentation_mask_sdxl_v1.safetensors]\n",
      "downloading... 100% 1.4 GiB/1.4 GiBiB\n",
      "<<<<<powerpaint_v2.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-inpaint/powerpaint_v2.safetensors\n",
      "downloading file [H-inpaint/powerpaint_v2.safetensors]\n",
      "downloading... 100% 469 MiB/469 MiB\n",
      "<<<<<pytorch_model.bin\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-inpaint/pytorch_model.bin\n",
      "downloading file [H-inpaint/pytorch_model.bin]\n",
      "downloading... 100% 470 MiB/470 MiB\n",
      ">>>> inpaint 下载完毕\n",
      "\n",
      "准备下载: upscale_models\n",
      "<<<<<4x_NMKD-Superscale-SP_178000_G.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-upscale_models/4x_NMKD-Superscale-SP_178000_G.pth\n",
      "downloading file [H-upscale_models/4x_NMKD-Superscale-SP_178000_G.pth]\n",
      "downloading... 100% 64 MiB/64 MiB\n",
      "<<<<<4x-ESRGAN.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-upscale_models/4x-ESRGAN.pth\n",
      "downloading file [H-upscale_models/4x-ESRGAN.pth]\n",
      "downloading... 100% 64 MiB/64 MiB\n",
      "<<<<<RealESRGAN_x4plus.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-upscale_models/RealESRGAN_x4plus.pth\n",
      "downloading file [H-upscale_models/RealESRGAN_x4plus.pth]\n",
      "downloading... 100% 64 MiB/64 MiB\n",
      "<<<<<1x_DeBLR.pth\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-upscale_models/1x_DeBLR.pth\n",
      "downloading file [H-upscale_models/1x_DeBLR.pth]\n",
      "downloading... 100% 64 MiB/64 MiB\n",
      ">>>> upscale_models 下载完毕\n",
      "\n",
      "准备下载: loras\n",
      "<<<<<LCM_LoRA_Weights_SDXL.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-loras/LCM_LoRA_Weights_SDXL.safetensors\n",
      "downloading file [H-loras/LCM_LoRA_Weights_SDXL.safetensors]\n",
      "downloading... 100% 376 MiB/376 MiB\n",
      ">>>> loras 下载完毕\n",
      "\n",
      "初始化完毕\n"
     ]
    }
   ],
   "source": [
    "# 初始化，仅下载单个sd15模型、单个sdxl模型，以及轻量化的controlnet模型\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh init\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh custom_nodes\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh checkpoint_sd15\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh checkpoint_sdxl\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh controlnet_sd15_v11_lite\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh sams\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh grounding-dino\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh facerestore\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh ic-light_lite\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh instantid\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh insightface\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh ipadapter_sd_lite\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh vae\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh inpaint\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh upscale_models\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh loras\n",
    "print(\"初始化完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b508b7-fbf0-4c20-89dd-7ed99724a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如需下载完整ipadapter模型\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh ipadapter_sd_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd13aba-0b5b-41a0-9742-47a18e9b1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如需下载完整controlnet模型\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh controlnet_sd15_v11_full\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh controlnet_sd15_v11_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea808e7f-cb1f-46b6-b79f-988e24955338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如需下载完整ICLight模型\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh ic-light_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ebe141-b9c2-403a-a7a9-4a44894facdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备下载: vae\n",
      "<<<<<vae-ft-mse-840000-ema-pruned.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-vae/vae-ft-mse-840000-ema-pruned.safetensors\n",
      "downloading file [H-vae/vae-ft-mse-840000-ema-pruned.safetensors]\n",
      "downloading... 100% 319 MiB/319 MiB\n",
      "<<<<<sdxl_vae.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-vae/sdxl_vae.safetensors\n",
      "downloading file [H-vae/sdxl_vae.safetensors]\n",
      "downloading... 100% 319 MiB/319 MiB\n",
      ">>>> vae 下载完毕\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 下载某些vae\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c55fc5-7a8f-4829-8a40-269ff7fe68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备下载: flux_dev\n",
      "<<<<<flux1-dev.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-Flux/flux1-dev.safetensors\n",
      "downloading file [H-Flux/flux1-dev.safetensors]\n",
      "downloading... 100% 22 GiB/22 GiBiBiB\n",
      "<<<<<clip_l.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-Flux/clip_l.safetensors\n",
      "downloading file [H-Flux/clip_l.safetensors]\n",
      "downloading... 100% 235 MiB/235 MiB\n",
      "<<<<<t5xxl_fp16.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-Flux/t5xxl_fp16.safetensors\n",
      "downloading file [H-Flux/t5xxl_fp16.safetensors]\n",
      "downloading... 100% 9.1 GiB/9.1 GiBiB\n",
      "<<<<<ae.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-Flux/ae.safetensors\n",
      "downloading file [H-Flux/ae.safetensors]\n",
      "downloading... 100% 320 MiB/320 MiB\n",
      "<<<<<flux_turbo_alpha.safetensors\n",
      ">>> download to  /root/autodl-tmp/models/LiuTxxx/H-Flux/flux_turbo_alpha.safetensors\n",
      "downloading file [H-Flux/flux_turbo_alpha.safetensors]\n",
      "downloading... 100% 662 MiB/662 MiB\n",
      ">>>> flux_dev 下载完毕\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 如需下载flux相关内容\n",
    "!bash /root/h-autodl/comfyui/scripts/init.sh flux_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda24573-1fab-4725-8710-6ee6a3a0f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "启动中……\n",
      "[START] Security scan\n",
      "[DONE] Security scan\n",
      "## ComfyUI-Manager: installing dependencies done.\n",
      "** ComfyUI startup time: 2024-11-05 20:12:32.644678\n",
      "** Platform: Linux\n",
      "** Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0]\n",
      "** Python executable: /root/miniconda3/envs/comfyenv/bin/python\n",
      "** ComfyUI Path: /root/autodl-tmp/ComfyUI\n",
      "** Log path: /root/autodl-tmp/ComfyUI/comfyui.log\n",
      "\n",
      "Prestartup times for custom nodes:\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n",
      "   0.3 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/BizyAir\n",
      "   1.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "\n",
      "Total VRAM 24210 MB, total RAM 1031435 MB\n",
      "pytorch version: 2.4.1\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA GeForce RTX 4090 : cudaMallocAsync\n",
      "Using pytorch cross attention\n",
      "[Prompt Server] web root: /root/autodl-tmp/ComfyUI/web\n",
      "/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[36;20m[comfy_mtb] | INFO -> loaded \u001b[96m86\u001b[0m nodes successfuly\u001b[0m\n",
      "\u001b[36;20m[comfy_mtb] | INFO -> Some nodes (2) could not be loaded. This can be ignored, but go to http://None:6006/mtb if you want more information.\u001b[0m\n",
      "\n",
      "\u001b[92m[rgthree-comfy] Loaded 42 fantastic nodes. 🎉\u001b[00m\n",
      "\n",
      "Total VRAM 24210 MB, total RAM 1031435 MB\n",
      "pytorch version: 2.4.1\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA GeForce RTX 4090 : cudaMallocAsync\n",
      "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider\n",
      "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
      "\u001b[1;35m### [START] ComfyUI AlekPet Nodes \u001b[1;34mv1.0.30\u001b[0m\u001b[1;35m ###\u001b[0m\n",
      "\u001b[92mNode -> GoogleTranslateNode: \u001b[93mGoogleTranslateCLIPTextEncodeNode, GoogleTranslateTextNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> ArgosTranslateNode: \u001b[93mArgosTranslateCLIPTextEncodeNode, ArgosTranslateTextNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> DeepTranslatorNode: \u001b[93mDeepTranslatorCLIPTextEncodeNode, DeepTranslatorTextNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> PoseNode: \u001b[93mPoseNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> ExtrasNode: \u001b[93mPreviewTextNode, HexToHueNode, ColorsCorrectNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> IDENode: \u001b[93mIDENode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> PainterNode: \u001b[93mPainterNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[1;35m### [END] ComfyUI AlekPet Nodes ###\u001b[0m\n",
      "\u001b[0;33m[ReActor]\u001b[0m - \u001b[38;5;173mSTATUS\u001b[0m - \u001b[0;32mRunning v0.5.1-b2 in ComfyUI\u001b[0m\n",
      "Torch version: 2.4.1\n",
      "[AnimateDiffEvo] - \u001b[0;31mERROR\u001b[0m - No motion models found. Please download one and place in: ['/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/models', '/root/autodl-tmp/ComfyUI/models/animatediff_models']\n",
      "### Loading: ComfyUI-Manager (V2.51.8)\n",
      "### ComfyUI Revision: UNKNOWN (The currently installed ComfyUI is not a Git repository)\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
      "Please 'pip install xformers'\n",
      "Nvidia APEX normalization not installed, using PyTorch LayerNorm\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
      "### Loading: ComfyUI-Inspire-Pack (V1.5.1)\n",
      "Display name '☁️BizyAir SetUnionControlNetType' might differ from the native display name.\n",
      "Display name '☁️BizyAir CLIPTextEncodeFlux' might differ from the native display name.\n",
      "Display name '☁️BizyAir FluxGuidance' might differ from the native display name.\n",
      "Display name '☁️BizyAir IPAdapterModelLoader' might differ from the native display name.\n",
      "Display name '☁️BizyAir IPAdapterAdvanced' might differ from the native display name.\n",
      "Display name '☁️BizyAir IPAdapterStyleComposition' might differ from the native display name.\n",
      "Display name '☁️BizyAir UltimateSDUpscale' might differ from the native display name.\n",
      "Display name '☁️BizyAir MinusZoneChatGLM3TextEncode' might differ from the native display name.\n",
      "Display name '☁️BizyAir SamplerCustomAdvanced' might differ from the native display name.\n",
      "Display name '☁️BizyAir BasicGuider' might differ from the native display name.\n",
      "Display name '☁️BizyAir BasicScheduler' might differ from the native display name.\n",
      "Display name '☁️BizyAir DualCLIPLoader' might differ from the native display name.\n",
      "Display name '☁️BizyAir KSamplerSelect' might differ from the native display name.\n",
      "Display name '☁️BizyAir RandomNoise' might differ from the native display name.\n",
      "Display name '☁️BizyAir InpaintModelConditioning' might differ from the native display name.\n",
      "\n",
      "\n",
      "\u001b[92m[BizyAir]\u001b[0m Model hosting service initialized.\n",
      "\n",
      "\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;33mCannot import name 'guidedFilter' from 'cv2.ximgproc'\n",
      "A few nodes cannot works properly, while most nodes are not affected. Please REINSTALL package 'opencv-contrib-python'.\n",
      "For detail refer to \u001b[4mhttps://github.com/chflame163/ComfyUI_LayerStyle/issues/5\u001b[0m\u001b[m\n",
      "--------------\n",
      "\u001b[91m ### Mixlab Nodes: \u001b[93mLoaded\n",
      "ChatGPT.available False\n",
      "edit_mask.available True\n",
      "## clip_interrogator_model not found: /root/autodl-tmp/ComfyUI/models/clip_interrogator/Salesforce/blip-image-captioning-base, pls download from https://huggingface.co/Salesforce/blip-image-captioning-base\n",
      "ClipInterrogator.available True\n",
      "## text_generator_model not found: /root/autodl-tmp/ComfyUI/models/prompt_generator/text2image-prompt-generator, pls download from https://huggingface.co/succinctly/text2image-prompt-generator/tree/main\n",
      "## zh_en_model not found: /root/autodl-tmp/ComfyUI/models/prompt_generator/opus-mt-zh-en, pls download from https://huggingface.co/Helsinki-NLP/opus-mt-zh-en/tree/main\n",
      "PromptGenerate.available True\n",
      "ChinesePrompt.available True\n",
      "RembgNode_.available True\n",
      "TripoSR.available\n",
      "MiniCPMNode.available\n",
      "Scenedetect.available False\n",
      "FishSpeech.available False\n",
      "SenseVoice.available False\n",
      "Whisper.available False\n",
      "fal-client## OK\n",
      "FalVideo.available\n",
      "\u001b[93m -------------- \u001b[0m\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] Crystools version: 1.19.0\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] CPU: Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz - Arch: x86_64 - OS: Linux 5.15.0-84-generic\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] Pynvml (Nvidia) initialized.\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] GPU/s:\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] 0) NVIDIA GeForce RTX 4090\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] NVIDIA Driver: 550.107.02\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
      "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.4 \u001b[92mLoaded\u001b[0m\n",
      "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Easy-Use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
      "\u001b[1;32m[Power Noise Suite]: 🦚🦚🦚 \u001b[93m\u001b[3mwark!\u001b[0m 🦚🦚🦚\n",
      "\u001b[1;32m[Power Noise Suite]:\u001b[0m Tamed \u001b[93m11\u001b[0m wild nodes.\n",
      "------------------------------------------\n",
      "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
      "------------------------------------------\n",
      "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
      "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
      "------------------------------------------\n",
      "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
      "--------------\n",
      "*ComfyUI_Jags_VectorMagic- nodes_loaded*\n",
      "--------------\n",
      "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
      "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
      "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
      "DWPose: Onnxruntime with acceleration providers detected\n",
      "\u001b[34mWAS Node Suite: \u001b[0mBlenderNeko's Advanced CLIP Text Encode found, attempting to enable `CLIPTextEncode` support.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0m`CLIPTextEncode (BlenderNeko Advanced + NSP)` node enabled under `WAS Suite/Conditioning` menu.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
      "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/root/autodl-tmp/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m219\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
      "\n",
      "\t\u001b[3m\u001b[93m\"Art is the lie that enables us to recognize the truth.\"\u001b[0m\u001b[3m - Friedrich Nietzsche\u001b[0m\n",
      "\n",
      "### Loading: ComfyUI-Impact-Pack (V7.10.3)\n",
      "### Loading: ComfyUI-Impact-Pack (Subpack: V0.7)\n",
      "[Impact Pack] Wildcards loading done.\n",
      "\u001b[36mEfficiency Nodes:\u001b[0m Attempting to add Control Net options to the 'HiRes-Fix Script' Node (comfyui_controlnet_aux add-on)...\u001b[92mSuccess!\u001b[0m\n",
      "Loaded Efficiency nodes from /root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui\n",
      "Loaded ControlNetPreprocessors nodes from /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
      "Loaded AdvancedControlNet nodes from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\n",
      "Could not find AnimateDiff nodes\n",
      "Loaded IPAdapter nodes from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
      "Loaded VideoHelperSuite from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n",
      "### Loading: ComfyUI-Impact-Pack (V7.10.3)\n",
      "Loaded ImpactPack nodes from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Impact-Pack\n",
      "[Impact Pack] Wildcards loading done.\n",
      "Web extensions folder found at /root/autodl-tmp/ComfyUI/web/extensions/ComfyLiterals\n",
      "\n",
      "\u001b[1mFrom Bmad Custom Nodes\u001b[0m\n",
      " \u001b[92mLoaded 125 nodes:\n",
      "  + api nodes (14)\n",
      "  + simple utility nodes (58)\n",
      "  + CV nodes (50)\n",
      "  + color clip ade20k node (1)\n",
      "  + extension dependent nodes (2)\n",
      "\u001b[0m\n",
      "\n",
      "Import times for custom nodes:\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/websocket_image_save.py\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/sdxl_utility.py\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-ZeroShot-MTrans\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/AIGODLIKE-COMFYUI-TRANSLATION\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/sdxl_prompt_styler\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-seamless-tiling\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-IC-Light-Native\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/cg-use-everywhere\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/cg-image-picker\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_ADV_CLIP_emb\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Florence2\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyLiterals\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-yanc\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-WD14-Tagger\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/masquerade-nodes-comfyui\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_InstantID\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/AuraSR-ComfyUI\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-AutomaticCFG\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-portrait-master\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Jags_VectorMagic\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/PowerNoiseSuite\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_JPS-Nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-PhotoMaker-Plus\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-inpaint-nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfy-image-saver\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/Comfyui_CXH_joy_caption\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_essentials\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-various\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/Derfuu_ComfyUI_ModdedNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-IC-Light\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/mikey_nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_UltimateSDUpscale\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-BrushNet\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-KJNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_bmad_nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/OneButtonPrompt\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/facerestore_cf\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Mira\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-art-venture\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_FaceAnalysis\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-BrushNet-Wrapper\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Impact-Pack\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/clipseg.py\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Crystools\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Inspire-Pack\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-ollama\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_segment_anything\n",
      "   0.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_LayerStyle\n",
      "   0.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/BizyAir\n",
      "   0.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Gemini\n",
      "   0.6 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui\n",
      "   0.6 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-reactor-node\n",
      "   0.7 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n",
      "   0.8 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/PuLID_ComfyUI\n",
      "   0.9 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Primere_Nodes\n",
      "   1.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes\n",
      "   1.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Custom_Nodes_AlekPet\n",
      "   1.5 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
      "   2.7 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfy_mtb\n",
      "\n",
      "Starting server\n",
      "\n",
      "To see the GUI go to: http://0.0.0.0:6006\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "[Deep Translator] Service: \"GoogleTranslator\"\n",
      "[Deep Translator] Proxy is enabled. Proxies: \n",
      "[Deep Translator] Authorization input field is empty!\n",
      "Deep Translator] Service detect language disabled! Services support: DeeplTranslator, QcriTranslator, LingueeTranslator, PonsTranslator, PapagoTranslator, BaiduTranslator, MyMemoryTranslator.\n",
      "The selected service has its own way of detecting the language.\n",
      "Property \"detect_lang_api_key\" in Authorization data is empty or incorrect!\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "\n",
      "Restarting... [Legacy Mode]\n",
      "\n",
      "\n",
      "[START] Security scan\n",
      "[DONE] Security scan\n",
      "## ComfyUI-Manager: installing dependencies done.\n",
      "** ComfyUI startup time: 2024-11-05 20:20:27.328729\n",
      "** Platform: Linux\n",
      "** Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:27:36) [GCC 11.2.0]\n",
      "** Python executable: /root/miniconda3/envs/comfyenv/bin/python\n",
      "** ComfyUI Path: /root/autodl-tmp/ComfyUI\n",
      "** Log path: /root/autodl-tmp/ComfyUI/comfyui.log\n",
      "\n",
      "Prestartup times for custom nodes:\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n",
      "   0.4 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/BizyAir\n",
      "   1.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "\n",
      "Total VRAM 24210 MB, total RAM 1031435 MB\n",
      "pytorch version: 2.4.1\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA GeForce RTX 4090 : cudaMallocAsync\n",
      "Using pytorch cross attention\n",
      "[Prompt Server] web root: /root/autodl-tmp/ComfyUI/web\n",
      "/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[36;20m[comfy_mtb] | INFO -> loaded \u001b[96m86\u001b[0m nodes successfuly\u001b[0m\n",
      "\u001b[36;20m[comfy_mtb] | INFO -> Some nodes (2) could not be loaded. This can be ignored, but go to http://None:6006/mtb if you want more information.\u001b[0m\n",
      "\n",
      "\u001b[92m[rgthree-comfy] Loaded 42 exciting nodes. 🎉\u001b[00m\n",
      "\n",
      "Total VRAM 24210 MB, total RAM 1031435 MB\n",
      "pytorch version: 2.4.1\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA GeForce RTX 4090 : cudaMallocAsync\n",
      "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: TensorrtExecutionProvider, CUDAExecutionProvider, CPUExecutionProvider\n",
      "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
      "\u001b[1;35m### [START] ComfyUI AlekPet Nodes \u001b[1;34mv1.0.30\u001b[0m\u001b[1;35m ###\u001b[0m\n",
      "\u001b[92mNode -> GoogleTranslateNode: \u001b[93mGoogleTranslateCLIPTextEncodeNode, GoogleTranslateTextNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> ArgosTranslateNode: \u001b[93mArgosTranslateCLIPTextEncodeNode, ArgosTranslateTextNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> DeepTranslatorNode: \u001b[93mDeepTranslatorCLIPTextEncodeNode, DeepTranslatorTextNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> PoseNode: \u001b[93mPoseNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> ExtrasNode: \u001b[93mPreviewTextNode, HexToHueNode, ColorsCorrectNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> IDENode: \u001b[93mIDENode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[92mNode -> PainterNode: \u001b[93mPainterNode\u001b[0m \u001b[92m[Loading] \u001b[0m\n",
      "\u001b[1;35m### [END] ComfyUI AlekPet Nodes ###\u001b[0m\n",
      "\u001b[0;33m[ReActor]\u001b[0m - \u001b[38;5;173mSTATUS\u001b[0m - \u001b[0;32mRunning v0.5.1-b2 in ComfyUI\u001b[0m\n",
      "Torch version: 2.4.1\n",
      "[AnimateDiffEvo] - \u001b[0;31mERROR\u001b[0m - No motion models found. Please download one and place in: ['/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved/models', '/root/autodl-tmp/ComfyUI/models/animatediff_models']\n",
      "### Loading: ComfyUI-Manager (V2.51.8)\n",
      "### ComfyUI Revision: UNKNOWN (The currently installed ComfyUI is not a Git repository)\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
      "Please 'pip install xformers'\n",
      "Nvidia APEX normalization not installed, using PyTorch LayerNorm\n",
      "### Loading: ComfyUI-Inspire-Pack (V1.5.1)\n",
      "Display name '☁️BizyAir SetUnionControlNetType' might differ from the native display name.\n",
      "Display name '☁️BizyAir CLIPTextEncodeFlux' might differ from the native display name.\n",
      "Display name '☁️BizyAir FluxGuidance' might differ from the native display name.\n",
      "Display name '☁️BizyAir IPAdapterModelLoader' might differ from the native display name.\n",
      "Display name '☁️BizyAir IPAdapterAdvanced' might differ from the native display name.\n",
      "Display name '☁️BizyAir IPAdapterStyleComposition' might differ from the native display name.\n",
      "Display name '☁️BizyAir UltimateSDUpscale' might differ from the native display name.\n",
      "Display name '☁️BizyAir MinusZoneChatGLM3TextEncode' might differ from the native display name.\n",
      "Display name '☁️BizyAir SamplerCustomAdvanced' might differ from the native display name.\n",
      "Display name '☁️BizyAir BasicGuider' might differ from the native display name.\n",
      "Display name '☁️BizyAir BasicScheduler' might differ from the native display name.\n",
      "Display name '☁️BizyAir DualCLIPLoader' might differ from the native display name.\n",
      "Display name '☁️BizyAir KSamplerSelect' might differ from the native display name.\n",
      "Display name '☁️BizyAir RandomNoise' might differ from the native display name.\n",
      "Display name '☁️BizyAir InpaintModelConditioning' might differ from the native display name.\n",
      "\n",
      "\n",
      "\u001b[92m[BizyAir]\u001b[0m Model hosting service initialized.\n",
      "\n",
      "\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;33mCannot import name 'guidedFilter' from 'cv2.ximgproc'\n",
      "A few nodes cannot works properly, while most nodes are not affected. Please REINSTALL package 'opencv-contrib-python'.\n",
      "For detail refer to \u001b[4mhttps://github.com/chflame163/ComfyUI_LayerStyle/issues/5\u001b[0m\u001b[m\n",
      "--------------\n",
      "\u001b[91m ### Mixlab Nodes: \u001b[93mLoaded\n",
      "ChatGPT.available False\n",
      "edit_mask.available True\n",
      "## clip_interrogator_model not found: /root/autodl-tmp/ComfyUI/models/clip_interrogator/Salesforce/blip-image-captioning-base, pls download from https://huggingface.co/Salesforce/blip-image-captioning-base\n",
      "ClipInterrogator.available True\n",
      "## text_generator_model not found: /root/autodl-tmp/ComfyUI/models/prompt_generator/text2image-prompt-generator, pls download from https://huggingface.co/succinctly/text2image-prompt-generator/tree/main\n",
      "## zh_en_model not found: /root/autodl-tmp/ComfyUI/models/prompt_generator/opus-mt-zh-en, pls download from https://huggingface.co/Helsinki-NLP/opus-mt-zh-en/tree/main\n",
      "PromptGenerate.available True\n",
      "ChinesePrompt.available True\n",
      "RembgNode_.available True\n",
      "TripoSR.available\n",
      "MiniCPMNode.available\n",
      "Scenedetect.available False\n",
      "FishSpeech.available False\n",
      "SenseVoice.available False\n",
      "Whisper.available False\n",
      "fal-client## OK\n",
      "FalVideo.available\n",
      "\u001b[93m -------------- \u001b[0m\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] Crystools version: 1.19.0\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] CPU: Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz - Arch: x86_64 - OS: Linux 5.15.0-84-generic\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] Pynvml (Nvidia) initialized.\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] GPU/s:\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] 0) NVIDIA GeForce RTX 4090\n",
      "[Crystools \u001b[0;32mINFO\u001b[0m] NVIDIA Driver: 550.107.02\n",
      "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.4 \u001b[92mLoaded\u001b[0m\n",
      "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Easy-Use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
      "\u001b[1;32m[Power Noise Suite]: 🦚🦚🦚 \u001b[93m\u001b[3mSup.\u001b[0m 🦚🦚🦚\n",
      "\u001b[1;32m[Power Noise Suite]:\u001b[0m Tamed \u001b[93m11\u001b[0m wild nodes.\n",
      "------------------------------------------\n",
      "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
      "------------------------------------------\n",
      "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
      "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
      "------------------------------------------\n",
      "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
      "--------------\n",
      "*ComfyUI_Jags_VectorMagic- nodes_loaded*\n",
      "--------------\n",
      "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
      "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
      "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0mBlenderNeko's Advanced CLIP Text Encode found, attempting to enable `CLIPTextEncode` support.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0m`CLIPTextEncode (BlenderNeko Advanced + NSP)` node enabled under `WAS Suite/Conditioning` menu.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
      "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/root/autodl-tmp/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m219\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
      "\n",
      "\t\u001b[3m\u001b[93m\"Art is the bridge that connects imagination to reality.\"\u001b[0m\u001b[3m - Unknown\u001b[0m\n",
      "\n",
      "### Loading: ComfyUI-Impact-Pack (V7.10.3)\n",
      "### Loading: ComfyUI-Impact-Pack (Subpack: V0.7)\n",
      "[Impact Pack] Wildcards loading done.\n",
      "\u001b[36mEfficiency Nodes:\u001b[0m Attempting to add Control Net options to the 'HiRes-Fix Script' Node (comfyui_controlnet_aux add-on)...\u001b[92mSuccess!\u001b[0m\n",
      "Loaded Efficiency nodes from /root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui\n",
      "Loaded ControlNetPreprocessors nodes from /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
      "Loaded AdvancedControlNet nodes from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\n",
      "Could not find AnimateDiff nodes\n",
      "Loaded IPAdapter nodes from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
      "Loaded VideoHelperSuite from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n",
      "### Loading: ComfyUI-Impact-Pack (V7.10.3)\n",
      "Loaded ImpactPack nodes from /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Impact-Pack\n",
      "[Impact Pack] Wildcards loading done.\n",
      "Web extensions folder found at /root/autodl-tmp/ComfyUI/web/extensions/ComfyLiterals\n",
      "\n",
      "\u001b[1mFrom Bmad Custom Nodes\u001b[0m\n",
      " \u001b[92mLoaded 125 nodes:\n",
      "  + api nodes (14)\n",
      "  + simple utility nodes (58)\n",
      "  + CV nodes (50)\n",
      "  + color clip ade20k node (1)\n",
      "  + extension dependent nodes (2)\n",
      "\u001b[0m\n",
      "\n",
      "Import times for custom nodes:\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/websocket_image_save.py\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/sdxl_utility.py\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-ZeroShot-MTrans\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/AIGODLIKE-COMFYUI-TRANSLATION\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-seamless-tiling\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-IC-Light-Native\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/sdxl_prompt_styler\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/cg-use-everywhere\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_ADV_CLIP_emb\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/cg-image-picker\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Florence2\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/masquerade-nodes-comfyui\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-yanc\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-WD14-Tagger\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyLiterals\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_InstantID\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/AuraSR-ComfyUI\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/PowerNoiseSuite\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-AutomaticCFG\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Jags_VectorMagic\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-PhotoMaker-Plus\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-inpaint-nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_IPAdapter_plus\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfy-image-saver\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_JPS-Nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Custom-Scripts\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-portrait-master\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-IC-Light\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/Comfyui_CXH_joy_caption\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-various\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/mikey_nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_essentials\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/Derfuu_ComfyUI_ModdedNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_UltimateSDUpscale\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-KJNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Advanced-ControlNet\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-BrushNet\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_bmad_nodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/OneButtonPrompt\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Mira\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/facerestore_cf\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-AnimateDiff-Evolved\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Impact-Pack\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_FaceAnalysis\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-art-venture\n",
      "   0.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-BrushNet-Wrapper\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/clipseg.py\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Crystools\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-ollama\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Inspire-Pack\n",
      "   0.1 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_segment_anything\n",
      "   0.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_LayerStyle\n",
      "   0.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/BizyAir\n",
      "   0.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Gemini\n",
      "   0.6 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Easy-Use\n",
      "   0.7 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui\n",
      "   0.8 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/PuLID_ComfyUI\n",
      "   0.9 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Primere_Nodes\n",
      "   1.0 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes\n",
      "   1.2 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI_Custom_Nodes_AlekPet\n",
      "   1.5 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
      "   2.4 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfyui-reactor-node\n",
      "   8.5 seconds: /root/autodl-tmp/ComfyUI/custom_nodes/comfy_mtb\n",
      "\n",
      "Starting server\n",
      "\n",
      "To see the GUI go to: http://0.0.0.0:6006\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "got prompt\n",
      "[Deep Translator] Service: \"GoogleTranslator\"\n",
      "[Deep Translator] Proxy is enabled. Proxies: http=127.0.0.1:20171\n",
      "[Deep Translator] Authorization input field is empty!\n",
      "Deep Translator] Service detect language disabled! Services support: DeeplTranslator, QcriTranslator, LingueeTranslator, PonsTranslator, PapagoTranslator, BaiduTranslator, MyMemoryTranslator.\n",
      "The selected service has its own way of detecting the language.\n",
      "Property \"detect_lang_api_key\" in Authorization data is empty or incorrect!\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "[Deep Translator] Error: HTTPSConnectionPool(host='translate.google.com', port=443): Max retries exceeded with url: /m?tl=en&sl=zh-CN&q=%E4%B8%80%E4%B8%AA%E5%A5%B3%E4%BA%BA (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f63ae2eede0>, 'Connection to translate.google.com timed out. (connect timeout=None)'))\n",
      "Prompt executed in 129.98 seconds\n",
      "Exception in thread Thread-1 (<lambda>):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 1058, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/aiohttp/streams.py\", line 643, in read\n",
      "    await self._waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/glob/manager_server.py\", line 1365, in <lambda>\n",
      "    threading.Thread(target=lambda: asyncio.run(default_cache_update())).start()\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/glob/manager_server.py\", line 1362, in default_cache_update\n",
      "    await asyncio.gather(a, b, c, d, e)\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/glob/manager_server.py\", line 1349, in get_cache\n",
      "    json_obj = await core.get_data(uri, True)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/glob/manager_core.py\", line 620, in get_data\n",
      "    async with session.get(uri) as resp:\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/aiohttp/client.py\", line 1357, in __aenter__\n",
      "    self._resp: _RetType = await self._coro\n",
      "                           ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/aiohttp/client.py\", line 688, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 1053, in start\n",
      "    with self._timer:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/comfyenv/lib/python3.12/site-packages/aiohttp/helpers.py\", line 749, in __exit__\n",
      "    raise asyncio.TimeoutError from exc_val\n",
      "TimeoutError\n",
      "got prompt\n",
      "[Deep Translator] Service: \"GoogleTranslator\"\n",
      "[Deep Translator] Proxy disabled or input field is empty!\n",
      "[Deep Translator] Authorization input field is empty!\n",
      "Deep Translator] Service detect language disabled! Services support: DeeplTranslator, QcriTranslator, LingueeTranslator, PonsTranslator, PapagoTranslator, BaiduTranslator, MyMemoryTranslator.\n",
      "The selected service has its own way of detecting the language.\n",
      "Property \"detect_lang_api_key\" in Authorization data is empty or incorrect!\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "[Deep Translator] Error: HTTPSConnectionPool(host='translate.google.com', port=443): Max retries exceeded with url: /m?tl=en&sl=zh-CN&q=%E4%B8%80%E4%B8%AA%E5%A5%B3%E4%BA%BA (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f63adf5f7a0>, 'Connection to translate.google.com timed out. (connect timeout=None)'))\n",
      "Prompt executed in 130.56 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe-lightbox.esm.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/photoswipe.min.css\n",
      "Use Proxy: http://127.0.0.1:20171\n",
      "FETCH DATA from: /root/autodl-tmp/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json [DONE]\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/pickr.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/classic.min.css\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/model-viewer.min.js\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.css\n",
      "/root/autodl-tmp/ComfyUI/custom_nodes/comfyui-mixlab-nodes/webApp/lib/juxtapose.min.js\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "got prompt\n",
      "Failed to validate prompt for output 43:\n",
      "* LoadImage 33:\n",
      "  - Custom validation failed for node: image - Invalid image file: clipspace/clipspace-mask-3048022.9000000004.png [input]\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 75:\n",
      "* LoadImage 21:\n",
      "  - Custom validation failed for node: image - Invalid image file: 4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp\n",
      "* ControlNetLoader 17:\n",
      "  - Value not in list: control_net_name: 'diffusion_pytorch_model.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* Lora Loader Stack (rgthree) 87:\n",
      "  - Value not in list: lora_01: 'DetailedEyes_V3.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_03: 'neg4all_bdsqlsz_xl_V91.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_02: '东方审美 _ BRairt.SDXL_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadImage 32:\n",
      "  - Custom validation failed for node: image - Invalid image file: da0ce58ec4bfd31cbb6c7484ac097583 (1).png\n",
      "* CR Multi-ControlNet Stack 141:\n",
      "  - Value not in list: controlnet_2: 'diffusers_xl_depth_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_3: 'thibaud_xl_openpose.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_1: 'diffusers_xl_canny_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* HighRes-Fix Script 54:\n",
      "  - Value not in list: pixel_upscaler: '1x_Filmify4K_v2_325000_G.pth' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "  - Value not in list: control_net_name: 'OpenPoseXL2.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* FaceDetailer 57:\n",
      "  - Return type mismatch between linked nodes: scheduler_func_opt, INT != SCHEDULER_FUNC\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 97:\n",
      "* ControlNetLoader 73:\n",
      "  - Value not in list: control_net_name: 'diffusion_tile_xl_f16.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 133:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 22:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 19:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 50:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 38:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 146:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 53:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 41:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 134:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 145:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 51:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 147:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 152:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 98:\n",
      "Output will be ignored\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/da0ce58ec4bfd31cbb6c7484ac097583 (1).png'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/clipspace/clipspace-mask-3048022.9000000004.png'\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "!!! Exception during processing !!! Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy/py/lora_stack.py\", line 37, in load_lora\n",
      "    model, clip = LoraLoader().load_lora(model, clip, lora_01, strength_01, strength_01)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 628, in load_lora\n",
      "    lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "\n",
      "Prompt executed in 1.50 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 43:\n",
      "* LoadImage 33:\n",
      "  - Custom validation failed for node: image - Invalid image file: clipspace/clipspace-mask-3048022.9000000004.png [input]\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 75:\n",
      "* LoadImage 21:\n",
      "  - Custom validation failed for node: image - Invalid image file: 4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp\n",
      "* ControlNetLoader 17:\n",
      "  - Value not in list: control_net_name: 'diffusion_pytorch_model.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* Lora Loader Stack (rgthree) 87:\n",
      "  - Value not in list: lora_01: 'DetailedEyes_V3.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_03: 'neg4all_bdsqlsz_xl_V91.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_02: '东方审美 _ BRairt.SDXL_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadImage 32:\n",
      "  - Custom validation failed for node: image - Invalid image file: da0ce58ec4bfd31cbb6c7484ac097583 (1).png\n",
      "* CR Multi-ControlNet Stack 141:\n",
      "  - Value not in list: controlnet_2: 'diffusers_xl_depth_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_3: 'thibaud_xl_openpose.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_1: 'diffusers_xl_canny_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* HighRes-Fix Script 54:\n",
      "  - Value not in list: pixel_upscaler: '1x_Filmify4K_v2_325000_G.pth' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "  - Value not in list: control_net_name: 'OpenPoseXL2.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* FaceDetailer 57:\n",
      "  - Return type mismatch between linked nodes: scheduler_func_opt, INT != SCHEDULER_FUNC\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 97:\n",
      "* ControlNetLoader 73:\n",
      "  - Value not in list: control_net_name: 'diffusion_tile_xl_f16.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 133:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 22:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 19:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 50:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 38:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 146:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 53:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 41:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 134:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 145:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 51:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 147:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 152:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 98:\n",
      "Output will be ignored\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/da0ce58ec4bfd31cbb6c7484ac097583 (1).png'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/clipspace/clipspace-mask-3048022.9000000004.png'\n",
      "!!! Exception during processing !!! Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy/py/lora_stack.py\", line 37, in load_lora\n",
      "    model, clip = LoraLoader().load_lora(model, clip, lora_01, strength_01, strength_01)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 628, in load_lora\n",
      "    lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "\n",
      "Prompt executed in 0.13 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 43:\n",
      "* LoadImage 33:\n",
      "  - Custom validation failed for node: image - Invalid image file: clipspace/clipspace-mask-3048022.9000000004.png [input]\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 75:\n",
      "* LoadImage 21:\n",
      "  - Custom validation failed for node: image - Invalid image file: 4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp\n",
      "* ControlNetLoader 17:\n",
      "  - Value not in list: control_net_name: 'diffusion_pytorch_model.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* Lora Loader Stack (rgthree) 87:\n",
      "  - Value not in list: lora_01: 'DetailedEyes_V3.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_03: 'neg4all_bdsqlsz_xl_V91.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_02: '东方审美 _ BRairt.SDXL_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadImage 32:\n",
      "  - Custom validation failed for node: image - Invalid image file: da0ce58ec4bfd31cbb6c7484ac097583 (1).png\n",
      "* CR Multi-ControlNet Stack 141:\n",
      "  - Value not in list: controlnet_2: 'diffusers_xl_depth_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_3: 'thibaud_xl_openpose.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_1: 'diffusers_xl_canny_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* HighRes-Fix Script 54:\n",
      "  - Value not in list: pixel_upscaler: '1x_Filmify4K_v2_325000_G.pth' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "  - Value not in list: control_net_name: 'OpenPoseXL2.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* FaceDetailer 57:\n",
      "  - Return type mismatch between linked nodes: scheduler_func_opt, INT != SCHEDULER_FUNC\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 97:\n",
      "* ControlNetLoader 73:\n",
      "  - Value not in list: control_net_name: 'diffusion_tile_xl_f16.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 133:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 22:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 19:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 50:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 38:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 146:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 53:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 41:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 134:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 145:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 51:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 147:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 152:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 98:\n",
      "Output will be ignored\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/da0ce58ec4bfd31cbb6c7484ac097583 (1).png'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/clipspace/clipspace-mask-3048022.9000000004.png'\n",
      "!!! Exception during processing !!! Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy/py/lora_stack.py\", line 37, in load_lora\n",
      "    model, clip = LoraLoader().load_lora(model, clip, lora_01, strength_01, strength_01)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 628, in load_lora\n",
      "    lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "\n",
      "Prompt executed in 0.13 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 43:\n",
      "* LoadImage 33:\n",
      "  - Custom validation failed for node: image - Invalid image file: clipspace/clipspace-mask-3048022.9000000004.png [input]\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 75:\n",
      "* LoadImage 21:\n",
      "  - Custom validation failed for node: image - Invalid image file: 4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp\n",
      "* ControlNetLoader 17:\n",
      "  - Value not in list: control_net_name: 'diffusion_pytorch_model.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* Lora Loader Stack (rgthree) 87:\n",
      "  - Value not in list: lora_01: 'DetailedEyes_V3.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_03: 'neg4all_bdsqlsz_xl_V91.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_02: '东方审美 _ BRairt.SDXL_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadImage 32:\n",
      "  - Custom validation failed for node: image - Invalid image file: da0ce58ec4bfd31cbb6c7484ac097583 (1).png\n",
      "* CR Multi-ControlNet Stack 141:\n",
      "  - Value not in list: controlnet_2: 'diffusers_xl_depth_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_3: 'thibaud_xl_openpose.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_1: 'diffusers_xl_canny_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* HighRes-Fix Script 54:\n",
      "  - Value not in list: pixel_upscaler: '1x_Filmify4K_v2_325000_G.pth' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "  - Value not in list: control_net_name: 'OpenPoseXL2.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* FaceDetailer 57:\n",
      "  - Return type mismatch between linked nodes: scheduler_func_opt, INT != SCHEDULER_FUNC\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 97:\n",
      "* ControlNetLoader 73:\n",
      "  - Value not in list: control_net_name: 'diffusion_tile_xl_f16.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 133:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 22:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 19:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 50:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 38:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 146:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 53:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 41:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 134:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 145:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 51:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 147:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 152:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 98:\n",
      "Output will be ignored\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/da0ce58ec4bfd31cbb6c7484ac097583 (1).png'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/clipspace/clipspace-mask-3048022.9000000004.png'\n",
      "!!! Exception during processing !!! Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy/py/lora_stack.py\", line 37, in load_lora\n",
      "    model, clip = LoraLoader().load_lora(model, clip, lora_01, strength_01, strength_01)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 628, in load_lora\n",
      "    lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "\n",
      "Prompt executed in 0.14 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 43:\n",
      "* LoadImage 33:\n",
      "  - Custom validation failed for node: image - Invalid image file: clipspace/clipspace-mask-3048022.9000000004.png [input]\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 75:\n",
      "* LoadImage 21:\n",
      "  - Custom validation failed for node: image - Invalid image file: 4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp\n",
      "* ControlNetLoader 17:\n",
      "  - Value not in list: control_net_name: 'diffusion_pytorch_model.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* Lora Loader Stack (rgthree) 87:\n",
      "  - Value not in list: lora_01: 'DetailedEyes_V3.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_03: 'neg4all_bdsqlsz_xl_V91.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_02: '东方审美 _ BRairt.SDXL_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadImage 32:\n",
      "  - Custom validation failed for node: image - Invalid image file: da0ce58ec4bfd31cbb6c7484ac097583 (1).png\n",
      "* CR Multi-ControlNet Stack 141:\n",
      "  - Value not in list: controlnet_2: 'diffusers_xl_depth_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_3: 'thibaud_xl_openpose.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_1: 'diffusers_xl_canny_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* HighRes-Fix Script 54:\n",
      "  - Value not in list: pixel_upscaler: '1x_Filmify4K_v2_325000_G.pth' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "  - Value not in list: control_net_name: 'OpenPoseXL2.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* FaceDetailer 57:\n",
      "  - Return type mismatch between linked nodes: scheduler_func_opt, INT != SCHEDULER_FUNC\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 97:\n",
      "* ControlNetLoader 73:\n",
      "  - Value not in list: control_net_name: 'diffusion_tile_xl_f16.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 133:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 22:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 19:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 50:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 38:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 146:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 53:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 41:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 134:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 145:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 51:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 147:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 152:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 98:\n",
      "Output will be ignored\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/da0ce58ec4bfd31cbb6c7484ac097583 (1).png'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/clipspace/clipspace-mask-3048022.9000000004.png'\n",
      "!!! Exception during processing !!! Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy/py/lora_stack.py\", line 37, in load_lora\n",
      "    model, clip = LoraLoader().load_lora(model, clip, lora_01, strength_01, strength_01)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 628, in load_lora\n",
      "    lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "\n",
      "Prompt executed in 0.15 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 43:\n",
      "* LoadImage 33:\n",
      "  - Custom validation failed for node: image - Invalid image file: clipspace/clipspace-mask-3048022.9000000004.png [input]\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 75:\n",
      "* LoadImage 21:\n",
      "  - Custom validation failed for node: image - Invalid image file: 4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp\n",
      "* ControlNetLoader 17:\n",
      "  - Value not in list: control_net_name: 'diffusion_pytorch_model.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* Lora Loader Stack (rgthree) 87:\n",
      "  - Value not in list: lora_01: 'DetailedEyes_V3.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_03: 'neg4all_bdsqlsz_xl_V91.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "  - Value not in list: lora_02: '东方审美 _ BRairt.SDXL_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadImage 32:\n",
      "  - Custom validation failed for node: image - Invalid image file: da0ce58ec4bfd31cbb6c7484ac097583 (1).png\n",
      "* CR Multi-ControlNet Stack 141:\n",
      "  - Value not in list: controlnet_2: 'diffusers_xl_depth_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_3: 'thibaud_xl_openpose.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "  - Value not in list: controlnet_1: 'diffusers_xl_canny_full.safetensors' not in ['None', 'control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* HighRes-Fix Script 54:\n",
      "  - Value not in list: pixel_upscaler: '1x_Filmify4K_v2_325000_G.pth' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "  - Value not in list: control_net_name: 'OpenPoseXL2.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "* FaceDetailer 57:\n",
      "  - Required input is missing: seed\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 97:\n",
      "* ControlNetLoader 73:\n",
      "  - Value not in list: control_net_name: 'diffusion_tile_xl_f16.safetensors' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 133:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 22:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 19:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 50:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 38:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 146:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 53:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 41:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 134:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 145:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 51:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 147:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 152:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 98:\n",
      "Output will be ignored\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/4c47f053c5a5d1d37bd7eebef3b57ab14a91c27b25c97d1626b6bc154a16d1ce (1).webp'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/da0ce58ec4bfd31cbb6c7484ac097583 (1).png'\n",
      "WARNING: [Errno 2] No such file or directory: '/root/autodl-tmp/ComfyUI/input/clipspace/clipspace-mask-3048022.9000000004.png'\n",
      "!!! Exception during processing !!! Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/rgthree-comfy/py/lora_stack.py\", line 37, in load_lora\n",
      "    model, clip = LoraLoader().load_lora(model, clip, lora_01, strength_01, strength_01)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 628, in load_lora\n",
      "    lora_path = folder_paths.get_full_path_or_raise(\"loras\", lora_name)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'loras' with filename 'DetailedEyes_V3.safetensors' not found.\n",
      "\n",
      "Prompt executed in 0.12 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 338:\n",
      "  - Value not in list: lora_name: '虚拟摄影 _ CN QHC青花盈伊颜_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* BrushNetLoader 394:\n",
      "  - Value not in list: brushnet: 'brushnet/random_mask_brushnet_ckpt.safetensors' not in ['brushnet/random_mask_sd15.safetensors', 'brushnet/segmentation_mask_sd15.safetensors', 'brushnet_xl/random_mask_sdxl.safetensors', 'brushnet_xl/segmentation_mask_sdxl_v1.safetensors', 'powerpaint/powerpaint_v2.safetensors']\n",
      "* UpscaleModelLoader 402:\n",
      "  - Value not in list: model_name: '4xUltrasharp_4xUltrasharpV10.pt' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadAndApplyICLightUnet 35:\n",
      "  - Value not in list: model_path: 'flux/iclight_sd15_fc.safetensors' not in ['iclight/iclight_sd15_fc.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.62 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 338:\n",
      "  - Value not in list: lora_name: '虚拟摄影 _ CN QHC青花盈伊颜_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.13 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 338:\n",
      "  - Value not in list: lora_name: '虚拟摄影 _ CN QHC青花盈伊颜_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.08 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.11 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.15 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "Requested to load SD1ClipModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 235.84423828125 True\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "----------------------------------------\n",
      "\u001b[36mEfficient Loader Models Cache:\u001b[0m\n",
      "Ckpt:\n",
      "  [1] majicmixRealistic_v7\n",
      "Vae:\n",
      "  [1] vae-ft-mse-840000-ema-pruned\n",
      "BrushNet model type: SD1.5\n",
      "BrushNet model file: /root/autodl-tmp/ComfyUI/models/inpaint/brushnet/random_mask_sd15.safetensors\n",
      "BrushNet SD1.5 model is loaded\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Processing interrupted\n",
      "Prompt executed in 26.62 seconds\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "Requested to load SD1ClipModel\n",
      "Loading 1 new model\n",
      "----------------------------------------\n",
      "\u001b[36mEfficient Loader Models Cache:\u001b[0m\n",
      "Ckpt:\n",
      "  [1] majicmixRealistic_v7\n",
      "Vae:\n",
      "  [1] vae-ft-mse-840000-ema-pruned\n",
      "LoadAndApplyICLightUnet: Checking IC-Light Unet path\n",
      "LoadAndApplyICLightUnet: Loading IC-Light Unet weights\n",
      "LoadAndApplyICLightUnet: Attempting to add patches with IC-Light Unet weights\n",
      "LoadAndApplyICLightUnet: Added LoadICLightUnet patches\n",
      "\u001b[33mINFO: Clip Vision model loaded from /root/autodl-tmp/ComfyUI/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\u001b[0m\n",
      "\u001b[33mINFO: IPAdapter model loaded from /root/autodl-tmp/ComfyUI/models/ipadapter/ip-adapter-faceid-plusv2_sd15.bin\u001b[0m\n",
      "\u001b[33mINFO: LoRA model loaded from /root/autodl-tmp/ComfyUI/models/loras/ip-adapter-faceid-plusv2_sd15_lora.safetensors\u001b[0m\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 338:\n",
      "  - Value not in list: lora_name: '虚拟摄影 _ CN QHC青花盈伊颜_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* BrushNetLoader 394:\n",
      "  - Value not in list: brushnet: 'brushnet/random_mask_brushnet_ckpt.safetensors' not in ['brushnet/random_mask_sd15.safetensors', 'brushnet/segmentation_mask_sd15.safetensors', 'brushnet_xl/random_mask_sdxl.safetensors', 'brushnet_xl/segmentation_mask_sdxl_v1.safetensors', 'powerpaint/powerpaint_v2.safetensors']\n",
      "* UpscaleModelLoader 402:\n",
      "  - Value not in list: model_name: '4xUltrasharp_4xUltrasharpV10.pt' not in ['1x_DeBLR.pth', '4x-ESRGAN.pth', '4x-UltraSharp.pth', '4x_NMKD-Superscale-SP_178000_G.pth', 'RealESRGAN_x4plus.pth']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* LoadAndApplyICLightUnet 35:\n",
      "  - Value not in list: model_path: 'flux/iclight_sd15_fc.safetensors' not in ['iclight/iclight_sd15_fc.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\u001b[33mINFO: InsightFace model loaded with CUDA provider\u001b[0m\n",
      "Processing interrupted\n",
      "Prompt executed in 80.92 seconds\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.10 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* CR LoRA Stack 424:\n",
      "  - Value not in list: lora_name_1: '虚拟摄影 _ turquoise flowers❀琼芳_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 338:\n",
      "  - Value not in list: lora_name: '虚拟摄影 _ CN QHC青花盈伊颜_v1.0.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "* Efficient Loader 37:\n",
      "  - Value not in list: lora_name: '林鹤-皮肤质感调整器-差异炼丹功能性lora模型_林鹤v1.safetensors' not in ['None', 'LCM_LoRA_Weights_SDXL.safetensors', 'ip-adapter-faceid-plusv2_sd15_lora.safetensors', 'ip-adapter-faceid-plusv2_sdxl_lora.safetensors', 'ip-adapter-faceid_sd15_lora.safetensors', 'ip-adapter-faceid_sdxl_lora.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 426:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 399:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 40:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 169:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 36:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 172:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "!!! Exception during processing !!! 'NoneType' object has no attribute 'lower'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/efficiency_nodes.py\", line 158, in efficientloader\n",
      "    model, clip = load_lora(lora_params, ckpt_name, my_unique_id, cache=lora_cache, ckpt_cache=ckpt_cache, cache_overwrite=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 372, in load_lora\n",
      "    lora_model, lora_clip = recursive_load_lora(lora_params, ckpt, clip, id, ckpt_cache, cache_overwrite, folder_paths)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/custom_nodes/efficiency-nodes-comfyui/tsc_utils.py\", line 363, in recursive_load_lora\n",
      "    lora_model, lora_clip = comfy.sd.load_lora_for_models(ckpt, clip, comfy.utils.load_torch_file(lora_path), strength_model, strength_clip)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/comfy/utils.py\", line 33, in load_torch_file\n",
      "    if ckpt.lower().endswith(\".safetensors\") or ckpt.lower().endswith(\".sft\"):\n",
      "       ^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'lower'\n",
      "\n",
      "Prompt executed in 0.12 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "BilboX LUTs path set to: /root/autodl-tmp/ComfyUI/custom_nodes/bilbox-comfyui/luts\n",
      "got prompt\n",
      "Requested to load SD1ClipModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 235.84423828125 True\n",
      "----------------------------------------\n",
      "\u001b[36mEfficient Loader Models Cache:\u001b[0m\n",
      "Ckpt:\n",
      "  [1] majicmixRealistic_v7\n",
      "Vae:\n",
      "  [1] vae-ft-mse-840000-ema-pruned\n",
      "Lora:\n",
      "  [1] base_ckpt: majicmixRealistic_v7\n",
      "      lora(mod,clip): 林鹤-皮肤质感调整器(0.3,1.0)\n",
      "LoadAndApplyICLightUnet: Checking IC-Light Unet path\n",
      "LoadAndApplyICLightUnet: Loading IC-Light Unet weights\n",
      "LoadAndApplyICLightUnet: Attempting to add patches with IC-Light Unet weights\n",
      "LoadAndApplyICLightUnet: Added LoadICLightUnet patches\n",
      "Requested to load SD1ClipModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 235.84423828125 True\n",
      "----------------------------------------\n",
      "\u001b[36mEfficient Loader Models Cache:\u001b[0m\n",
      "Ckpt:\n",
      "  [1] majicmixRealistic_v7\n",
      "Vae:\n",
      "  [1] vae-ft-mse-840000-ema-pruned\n",
      "Lora:\n",
      "  [1] base_ckpt: majicmixRealistic_v7\n",
      "      lora(mod,clip): 汉服-青花(0.75,1.0)\n",
      "      lora(mod,clip): turquoise_flowers_v1.0(0.35,1.0)\n",
      "BrushNet model type: SD1.5\n",
      "BrushNet model file: /root/autodl-tmp/ComfyUI/models/inpaint/brushnet/random_mask_sd15.safetensors\n",
      "BrushNet SD1.5 model is loaded\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "Requested to load CLIPVisionModelProjection\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1208.09814453125 True\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 512, 3]) mask.shape = torch.Size([1, 768, 512])\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 64]) interpolated_mask shape = torch.Size([1, 1, 96, 64])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Caching ONNXRuntime session yolox_l.onnx...\n",
      "DWPose: Caching TorchScript module dw-ll_ucoco_384_bs5.torchscript.pt on ...\n",
      "DWPose: Bbox 7087.52ms\n",
      "DWPose: Pose 240.23ms on 1 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Requested to load ControlNet\n",
      "Loading 2 new models\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "loaded completely 0.0 689.0852355957031 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 64]) , CL torch.Size([1, 5, 96, 64]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 64]) , CL torch.Size([1, 5, 96, 64]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.55it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 1024x1536\n",
      "Image size: 512x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.42it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.46it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.58it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.52it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.78it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.59it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.58it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.44it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.95it/s]\n",
      "Prompt executed in 109.02 seconds\n",
      "got prompt\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 433, 3]) mask.shape = torch.Size([1, 768, 433])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 54]) interpolated_mask shape = torch.Size([1, 1, 96, 54])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 18.11ms\n",
      "DWPose: Pose 12738.19ms on 1 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 54]) , CL torch.Size([1, 5, 96, 54]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 54]) , CL torch.Size([1, 5, 96, 54]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.68it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 864x1536\n",
      "Image size: 432x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.30it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.42it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.53it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.60it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.63it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.48it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.41it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.53it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  7.32it/s]\n",
      "Prompt executed in 121.50 seconds\n",
      "got prompt\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 754, 3]) mask.shape = torch.Size([1, 768, 754])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 94]) interpolated_mask shape = torch.Size([1, 1, 96, 94])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 20.66ms\n",
      "DWPose: Pose 25.25ms on 2 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 94]) , CL torch.Size([1, 5, 96, 94]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 94]) , CL torch.Size([1, 5, 96, 94]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.30it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 1504x1536\n",
      "Image size: 752x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.35it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.42it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.37it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.69it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.67it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.45it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.53it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  6.44it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:07<00:00,  3.24it/s]\n",
      "Prompt executed in 126.74 seconds\n",
      "got prompt\n",
      "Failed to validate prompt for output 399:\n",
      "* BrushNet 393:\n",
      "  - Required input is missing: mask\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 430:\n",
      "* (prompt):\n",
      "  - Required input is missing: images\n",
      "* PreviewImage 430:\n",
      "  - Required input is missing: images\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 375:\n",
      "Output will be ignored\n",
      "Prompt executed in 0.58 seconds\n",
      "got prompt\n",
      "Failed to validate prompt for output 430:\n",
      "* (prompt):\n",
      "  - Required input is missing: images\n",
      "* PreviewImage 430:\n",
      "  - Required input is missing: images\n",
      "Output will be ignored\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 754, 3]) mask.shape = torch.Size([1, 768, 754])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 94]) interpolated_mask shape = torch.Size([1, 1, 96, 94])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 94]) , CL torch.Size([1, 5, 96, 94]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 94]) , CL torch.Size([1, 5, 96, 94]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.08it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Prompt executed in 30.17 seconds\n",
      "got prompt\n",
      "Failed to validate prompt for output 430:\n",
      "* (prompt):\n",
      "  - Required input is missing: images\n",
      "* PreviewImage 430:\n",
      "  - Required input is missing: images\n",
      "Output will be ignored\n",
      "Requested to load SD1ClipModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 235.84423828125 True\n",
      "----------------------------------------\n",
      "\u001b[36mEfficient Loader Models Cache:\u001b[0m\n",
      "Ckpt:\n",
      "  [1] majicmixRealistic_v7\n",
      "Vae:\n",
      "  [1] vae-ft-mse-840000-ema-pruned\n",
      "Lora:\n",
      "  [1] base_ckpt: majicmixRealistic_v7\n",
      "      lora(mod,clip): 林鹤-皮肤质感调整器(0.3,1.0)\n",
      "LoadAndApplyICLightUnet: Checking IC-Light Unet path\n",
      "LoadAndApplyICLightUnet: Loading IC-Light Unet weights\n",
      "LoadAndApplyICLightUnet: Attempting to add patches with IC-Light Unet weights\n",
      "LoadAndApplyICLightUnet: Added LoadICLightUnet patches\n",
      "\u001b[33mINFO: Clip Vision model loaded from /root/autodl-tmp/ComfyUI/models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors\u001b[0m\n",
      "\u001b[33mINFO: IPAdapter model loaded from /root/autodl-tmp/ComfyUI/models/ipadapter/ip-adapter-faceid-plusv2_sd15.bin\u001b[0m\n",
      "\u001b[33mINFO: LoRA model loaded from /root/autodl-tmp/ComfyUI/models/loras/ip-adapter-faceid-plusv2_sd15_lora.safetensors\u001b[0m\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /root/autodl-tmp/ComfyUI/models/insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "\u001b[33mINFO: InsightFace model loaded with CUDA provider\u001b[0m\n",
      "Processing interrupted\n",
      "Prompt executed in 77.11 seconds\n",
      "got prompt\n",
      "Failed to validate prompt for output 425:\n",
      "* ControlNetLoader 406:\n",
      "  - Value not in list: control_net_name: 'control_v11u_sd15_tile.pth' not in ['control_hed.safetensors', 'control_v11f1e_sd15_tile.pth', 'control_v11f1p_sd15_depth.pth', 'control_v11p_sd15_canny.pth', 'control_v11p_sd15_inpaint.pth', 'control_v11p_sd15_lineart.pth', 'control_v11p_sd15_openpose.pth', 'control_v11p_sd15_scribble.pth', 'control_v11p_sd15_seg.pth', 'control_v11p_sd15_softedge.pth', 'instantid/diffusion_pytorch_model.safetensors']\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 430:\n",
      "Output will be ignored\n",
      "Failed to validate prompt for output 433:\n",
      "Output will be ignored\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "Requested to load CLIPVisionModelProjection\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1208.09814453125 True\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 504, 3]) mask.shape = torch.Size([1, 768, 504])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 63]) interpolated_mask shape = torch.Size([1, 1, 96, 63])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 20.62ms\n",
      "DWPose: Pose 22.40ms on 1 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 63]) , CL torch.Size([1, 5, 96, 63]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 63]) , CL torch.Size([1, 5, 96, 63]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.37it/s]\n",
      "!!! Exception during processing !!! Model in folder 'controlnet' with filename 'control_v11u_sd15_tile.pth' not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 323, in execute\n",
      "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 198, in get_output_data\n",
      "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 169, in _map_node_over_list\n",
      "    process_inputs(input_dict, i)\n",
      "  File \"/root/autodl-tmp/ComfyUI/execution.py\", line 158, in process_inputs\n",
      "    results.append(getattr(obj, func)(**inputs))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/nodes.py\", line 758, in load_controlnet\n",
      "    controlnet_path = folder_paths.get_full_path_or_raise(\"controlnet\", control_net_name)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/ComfyUI/folder_paths.py\", line 279, in get_full_path_or_raise\n",
      "    raise FileNotFoundError(f\"Model in folder '{folder_name}' with filename '{filename}' not found.\")\n",
      "FileNotFoundError: Model in folder 'controlnet' with filename 'control_v11u_sd15_tile.pth' not found.\n",
      "\n",
      "Prompt executed in 34.11 seconds\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n",
      "got prompt\n",
      "Canva size: 1008x1536\n",
      "Image size: 504x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.50it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.90it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.90it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.57it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.85it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.95it/s]\n",
      " 20%|████████▊                                   | 5/25 [00:01<00:04,  4.07it/s]\n",
      "Processing interrupted\n",
      "Prompt executed in 37.58 seconds\n",
      "got prompt\n",
      "Canva size: 1008x1536\n",
      "Image size: 504x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.81it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.85it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.85it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.78it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.85it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.88it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.95it/s]\n",
      " 56%|████████████████████████                   | 14/25 [00:03<00:02,  4.61it/s]\n",
      "Processing interrupted\n",
      "Prompt executed in 43.64 seconds\n",
      "got prompt\n",
      "Canva size: 1008x1536\n",
      "Image size: 504x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.79it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.71it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.86it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.96it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.96it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.94it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.02it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.03it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Processing interrupted\n",
      "Prompt executed in 70.15 seconds\n",
      "got prompt\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.02it/s]\n",
      "Processing interrupted\n",
      "Prompt executed in 46.40 seconds\n",
      "got prompt\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 512, 3]) mask.shape = torch.Size([1, 768, 512])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 64]) interpolated_mask shape = torch.Size([1, 1, 96, 64])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 19.00ms\n",
      "DWPose: Pose 19.25ms on 1 people\n",
      "\n",
      "Requested to load ControlNet\n",
      "Requested to load BaseModel\n",
      "Loading 2 new models\n",
      "loaded completely 0.0 689.0852355957031 True\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 64]) , CL torch.Size([1, 5, 96, 64]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 64]) , CL torch.Size([1, 5, 96, 64]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.23it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 1024x1536\n",
      "Image size: 512x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.89it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.59it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.94it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.34it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.78it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.73it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.79it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.79it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.97it/s]\n",
      "Prompt executed in 147.66 seconds\n",
      "got prompt\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "Processing interrupted\n",
      "Prompt executed in 25.36 seconds\n",
      "got prompt\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 655, 3]) mask.shape = torch.Size([1, 768, 655])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 81]) interpolated_mask shape = torch.Size([1, 1, 96, 81])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 18.10ms\n",
      "DWPose: Pose 19.51ms on 1 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 81]) , CL torch.Size([1, 5, 96, 81]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 81]) , CL torch.Size([1, 5, 96, 81]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:05<00:00,  5.10it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 1296x1536\n",
      "Image size: 648x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.87it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.80it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.94it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.87it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.96it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.97it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.90it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.99it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "got prompt\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Processing interrupted\n",
      "Prompt executed in 127.12 seconds\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 392, 3]) mask.shape = torch.Size([1, 768, 392])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 49]) interpolated_mask shape = torch.Size([1, 1, 96, 49])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 17.71ms\n",
      "DWPose: Pose 22.59ms on 1 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 49]) , CL torch.Size([1, 5, 96, 49]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 49]) , CL torch.Size([1, 5, 96, 49]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:06<00:00,  4.64it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 784x1536\n",
      "Image size: 392x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.79it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.85it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.86it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.06it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.94it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.03it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.09it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.15it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  8.27it/s]\n",
      "Prompt executed in 140.56 seconds\n",
      "moving '/root/autodl-tmp/ComfyUI/user/default/workflows/差东西/需要翻译+embedding+xl_crtlnet.json' -> '/root/autodl-tmp/ComfyUI/user/default/workflows/效果还行/brush+ctrl+ipa+iclight.json'\n",
      "got prompt\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32m Processed 1 mask(s).\u001b[m\n",
      "Base model type: SD1.5\n",
      "BrushNet image.shape = torch.Size([1, 768, 433, 3]) mask.shape = torch.Size([1, 768, 433])\n",
      "BrushNet CL: image_latents shape = torch.Size([1, 4, 96, 54]) interpolated_mask shape = torch.Size([1, 1, 96, 54])\n",
      "BrushNet: negative prompt more than 75 tokens: torch.Size([1, 462, 768]) multiplying prompt_embeds\n",
      "BrushNet: positive conditioning has not pooled_output\n",
      "BrushNet: negative conditioning has not pooled_output\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/yzd-v/DWPose/yolox_l.onnx\n",
      "model_path is /root/autodl-tmp/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts/hr16/DWPose-TorchScript-BatchSize5/dw-ll_ucoco_384_bs5.torchscript.pt\n",
      "\n",
      "DWPose: Using yolox_l.onnx for bbox detection and dw-ll_ucoco_384_bs5.torchscript.pt for pose estimation\n",
      "DWPose: Bbox 20.08ms\n",
      "DWPose: Pose 20.40ms on 1 people\n",
      "\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 54]) , CL torch.Size([1, 5, 96, 54]) dtype torch.float16\n",
      "BrushNet inference, step = 0: image batch = 1, got 1 latents, starting from 0\n",
      "BrushNet inference: sample torch.Size([1, 4, 96, 54]) , CL torch.Size([1, 5, 96, 54]) dtype torch.float16\n",
      "100%|███████████████████████████████████████████| 30/30 [00:06<00:00,  4.98it/s]\n",
      "Requested to load AutoencoderKL\n",
      "Loading 1 new model\n",
      "loaded completely 0.0 159.55708122253418 True\n",
      "Canva size: 864x1536\n",
      "Image size: 432x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.21it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.16it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.04it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.16it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.17it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.08it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.10it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.00it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Processing interrupted\n",
      "Prompt executed in 116.21 seconds\n",
      "got prompt\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "Canva size: 864x1536\n",
      "Image size: 432x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.92it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.91it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.82it/s]\n",
      " 20%|████████▊                                   | 5/25 [00:01<00:05,  3.96it/s]\n",
      "Processing interrupted\n",
      "Prompt executed in 19.91 seconds\n",
      "got prompt\n",
      "Canva size: 864x1536\n",
      "Image size: 432x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.37it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.90it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.96it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.64it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.95it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.47it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:05<00:00,  4.99it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.05it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Processing interrupted\n",
      "Prompt executed in 92.50 seconds\n",
      "got prompt\n",
      "Canva size: 864x1536\n",
      "Image size: 432x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.84it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.01it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.12it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.13it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.15it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.15it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.17it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.17it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  7.34it/s]\n",
      "Prompt executed in 101.67 seconds\n",
      "got prompt\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  7.30it/s]\n",
      "Prompt executed in 16.59 seconds\n",
      "got prompt\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  7.31it/s]\n",
      "Prompt executed in 18.09 seconds\n",
      "got prompt\n",
      "Canva size: 864x1536\n",
      "Image size: 432x768\n",
      "Scale factor: 2\n",
      "Upscaling iteration 1 with scale factor 2\n",
      "Tile size: 768x768\n",
      "Tiles amount: 4\n",
      "Grid: 2x2\n",
      "Redraw enabled: True\n",
      "Seams fix mode: HALF_TILE\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.15it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.19it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.26it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.50it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  5.76it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.15it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.06it/s]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:04<00:00,  6.05it/s]\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mShadow & Highlight Mask Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/sams/sam_vit_h_4b8939.pth\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/GroundingDINO_SwinB.cfg.py\n",
      "final text_encoder_type: bert-base-uncased\n",
      "using extra model: /root/autodl-tmp/ComfyUI/models/grounding-dino/groundingdino_swinb_cogcoor.pth\n",
      "# 😺dzNodes: LayerStyle -> \u001b[1;32mSegmentAnythingUltra V2 Processed 1 image(s).\u001b[m\n",
      "Requested to load BaseModel\n",
      "Loading 1 new model\n",
      "WARNING SHAPE MISMATCH diffusion_model.input_blocks.0.0.weight WEIGHT NOT MERGED torch.Size([320, 8, 3, 3]) != torch.Size([320, 4, 3, 3])\n",
      "IC-Light: Merged with diffusion_model.input_blocks.0.0.weight channel changed from torch.Size([320, 4, 3, 3]) to [320, 8, 3, 3]\n",
      "loaded completely 0.0 1639.406135559082 True\n",
      "100%|███████████████████████████████████████████| 25/25 [00:03<00:00,  7.35it/s]\n",
      "Prompt executed in 103.75 seconds\n",
      "moving '/root/autodl-tmp/ComfyUI/user/default/workflows/效果还行/brush+ctrl+ipa+iclight.json' -> '/root/autodl-tmp/ComfyUI/user/default/workflows/效果还行/brush+ctrl+ipa+iclight+细节+高光.json'\n",
      "moving '/root/autodl-tmp/ComfyUI/user/default/workflows/效果还行/brush+ctrl+ipa+iclight+细节+高光.json' -> '/root/autodl-tmp/ComfyUI/user/default/workflows/brush+ctrl+ipa+iclight+细节+高光.json'\n",
      "fatal: No names found, cannot describe anything.\n",
      "Failed to get ComfyUI version: Command '['git', 'describe', '--tags']' returned non-zero exit status 128.\n"
     ]
    }
   ],
   "source": [
    "# 启动\n",
    "!bash /root/h-autodl/comfyui/scripts/start.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f156e-7c0a-4e00-b896-d9bef5b6a89c",
   "metadata": {
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
